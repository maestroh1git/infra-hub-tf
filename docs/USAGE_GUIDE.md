# Real-World Usage Guide: Deploying maestrohwithit Property Booking API

## Overview

This guide walks through the **complete lifecycle** of deploying the **maestrohwithit Property Booking API** - a microservices-based application for managing property listings, bookings, and payments. We'll follow best practices from initial development through production deployment.

## üì± Application Overview

**maestrohwithit Property Booking API** is a REST API that enables:
- Property listing management
- Real-time booking system
- Payment processing integration
- User authentication & authorization
- Analytics and reporting

**Tech Stack:**
- **Backend:** Node.js (Express.js)
- **Database:** PostgreSQL (RDS)
- **Container:** Docker + EKS
- **Cache:** Redis (ElastiCache)
- **Storage:** S3 for images
- **CDN:** CloudFront

## üéØ Project Lifecycle Stages

```
Stage 1: Development Setup ‚Üí 
Stage 2: Development Deployment ‚Üí
Stage 3: Staging Testing ‚Üí
Stage 4: Production Launch ‚Üí
Stage 5: Scaling & Optimization ‚Üí
Stage 6: Disaster Recovery Testing
```

---

## Stage 1: Development Setup (Week 1)

### Day 1: Infrastructure Bootstrap

#### 1.1 Initial AWS Setup

```bash
# Configure AWS CLI
aws configure
# AWS Access Key ID: AKIAIOSFODNN7EXAMPLE
# AWS Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# Default region name: us-east-2
# Default output format: json

# Verify credentials
aws sts get-caller-identity
```

**Output:**
```json
{
  "UserId": "AIDAI...",
  "Account": "123456789012",
  "Arn": "arn:aws:iam::123456789012:user/devops-user"
}
```

#### 1.2 Create Remote State Backend

```bash
# Create S3 bucket for Terraform state
aws s3api create-bucket \
  --bucket maestrohwithit-infra-bucket \
  --region us-east-2 \
  --create-bucket-configuration LocationConstraint=us-east-2

# Enable versioning
aws s3api put-bucket-versioning \
  --bucket maestrohwithit-infra-bucket \
  --versioning-configuration Status=Enabled

# Enable encryption
aws s3api put-bucket-encryption \
  --bucket maestrohwithit-infra-bucket \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'

# Create DynamoDB table for state locking
aws dynamodb create-table \
  --table-name maestrohwithit-backend-state-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST \
  --region us-east-2 \
  --tags Key=Application,Value=maestrohwithit Key=Purpose,Value=terraform-state-lock
```

#### 1.3 Create SSH Key Pair

```bash
# Generate SSH key for EC2 instances
ssh-keygen -t rsa -b 4096 -f ~/.ssh/maestrohwithit-dev-key -C "maestrohwithit-dev"

# Import to AWS
aws ec2 import-key-pair \
  --key-name maestrohwithit-dev-key \
  --public-key-material fileb://~/.ssh/maestrohwithit-dev-key.pub \
  --region us-east-2
```

#### 1.4 Clone Infrastructure Repository

```bash
# Clone the repo
git clone https://github.com/maestrohwithit-USA/maestrohwithit-infra.git
cd maestrohwithit-infra

# Install pre-commit hooks
pip install pre-commit
pre-commit install

# Test pre-commit
pre-commit run --all-files
```

### Day 2: Development Environment Deployment

#### 2.1 Update Configuration

```bash
cd environments/dev

# Edit terraform.tfvars
nano terraform.tfvars
```

**Key configurations to update:**
```hcl
# environments/dev/terraform.tfvars

# Update AMI (find latest Amazon Linux 2)
ami_id = "ami-0c55b159cbfafe1f0"  # Replace with latest

# Update your actual key name
key_name = "maestrohwithit-dev-key"

# Update subnet and SG IDs after VPC creation (initially leave empty)
subnet_ids = []
security_group_ids = []

# Keep other values as-is for initial deployment
```

#### 2.2 Deploy VPC First

```bash
# Initialize Terraform
terraform init

# Preview VPC creation
terraform plan -target=module.vpc -var-file=terraform.tfvars

# Create VPC
terraform apply -target=module.vpc -var-file=terraform.tfvars
```

**Output:**
```
Apply complete! Resources: 15 added, 0 changed, 0 destroyed.

Outputs:
vpc_id = "vpc-0a1b2c3d4e5f6g7h8"
public_subnet_ids = [
  "subnet-0a1b2c3d",
  "subnet-0e5f6g7h",
  "subnet-0i9j0k1l",
]
app_subnet_ids = [
  "subnet-0m2n3o4p",
  "subnet-0q5r6s7t",
  "subnet-0u8v9w0x",
]
```

#### 2.3 Update VPC ID and Deploy Remaining Resources

```bash
# Update terraform.tfvars with actual VPC ID
sed -i '' 's/vpc-placeholder/vpc-0a1b2c3d4e5f6g7h8/' terraform.tfvars

# Get subnet IDs for EC2
export SUBNET_ID=$(terraform output -json public_subnet_ids | jq -r '.[0]')

# Deploy remaining infrastructure
terraform plan -var-file=terraform.tfvars
terraform apply -var-file=terraform.tfvars
```

**Resources Created:**
- ‚úÖ VPC with 3 AZs
- ‚úÖ 3 Public subnets, 3 Private subnets
- ‚úÖ NAT Gateway
- ‚úÖ Internet Gateway
- ‚úÖ Security Groups
- ‚úÖ EC2 instance (t3.micro)
- ‚úÖ DynamoDB for state locks
- ‚úÖ IAM roles and policies

### Day 3: Install Application Dependencies

#### 3.1 Connect to EC2 Instance

```bash
# Get EC2 public IP
EC2_IP=$(terraform output -json ec2_public_ips | jq -r '.[0]')

# SSH into instance
ssh -i ~/.ssh/maestrohwithit-dev-key ec2-user@$EC2_IP
```

#### 3.2 Setup Application Environment

```bash
# On EC2 instance

# Update system
sudo yum update -y

# Install Node.js
curl -sL https://rpm.nodesource.com/setup_18.x | sudo bash -
sudo yum install -y nodejs

# Install Docker
sudo yum install -y docker
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -a -G docker ec2-user

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" \
  -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installations
node --version  # v18.x.x
docker --version
docker-compose --version
```

### Day 4: Create RDS Database

#### 4.1 Create Database Secret

```bash
# Create database password in Secrets Manager
aws secretsmanager create-secret \
  --name /maestrohwithit/dev/rds/master-password \
  --description "Master password for dev RDS instance" \
  --secret-string '{
    "username":"maestrohwithitadmin",
    "password":"DevPass123!SecureRandom",
    "engine":"postgres",
    "host":"",
    "port":"5432",
    "dbname":"maestrohwithit_dev"
  }' \
  --region us-east-2 \
  --tags Key=Environment,Value=dev Key=Application,Value=maestrohwithit
```

#### 4.2 Deploy RDS Module

Create RDS configuration:

```bash
# Create new file: environments/dev/database.tf
cat > database.tf <<'EOF'
module "rds" {
  source = "../../modules/rds"

  environment  = var.environment
  application  = var.application
  owner        = var.owner
  cost_center  = var.cost_center

  # Database configuration
  db_engine           = "postgres"
  db_instance_class   = "db.t3.micro"
  db_storage_size     = 20
  db_storage_type     = "gp3"
  db_username         = "maestrohwithitadmin"
  
  # Let AWS manage password
  set_secret_manager_password = true
  set_db_password            = false

  # Network
  subnet_ids = module.vpc.app_subnet_ids

  # Security
  from_port   = 5432
  to_port     = 5432
  protocol    = "tcp"
  cidr_block  = [var.vpc_cidr_block]

  # Backup
  backup_retention_period = 0  # No backups for dev
  multi_az                = false
  publicly_accessible     = false
  skip_final_snapshot     = true
  apply_immediately       = true
  
  delete_automated_backups = true
  copy_tags_to_snapshot   = false

  tags = var.tags
}

output "rds_endpoint" {
  value       = module.rds.rds_endpoint
  description = "RDS instance endpoint"
}

output "rds_secret_arn" {
  value       = module.rds.master_user_secret_arn
  description = "ARN of the secret containing RDS credentials"
}
EOF

# Apply
terraform apply -var-file=terraform.tfvars
```

**Output:**
```
Apply complete! Resources: 3 added, 0 changed, 0 destroyed.

Outputs:
rds_endpoint = "dev-maestrohwithit-db.abc123xyz.us-east-2.rds.amazonaws.com:5432"
rds_secret_arn = "arn:aws:secretsmanager:us-east-2:123456789012:secret:rds!db-abc123"
```

---

## Stage 2: Development Deployment (Week 2)

### Day 5: Deploy Application Code

#### 5.1 Clone Application Repository

```bash
# On your local machine
git clone https://github.com/maestrohwithit-USA/property-booking-api.git
cd property-booking-api
```

**Application Structure:**
```
property-booking-api/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ propertyController.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bookingController.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ userController.js
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Property.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Booking.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ User.js
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.js
‚îÇ   ‚îî‚îÄ‚îÄ server.js
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ .env.example
```

#### 5.2 Create Environment Configuration

```bash
# Retrieve database credentials
aws secretsmanager get-secret-value \
  --secret-id /maestrohwithit/dev/rds/master-password \
  --region us-east-2 \
  --query SecretString \
  --output text | jq -r '.password'

# Create .env file
cat > .env <<EOF
NODE_ENV=development
PORT=3000

# Database
DB_HOST=dev-maestrohwithit-db.abc123xyz.us-east-2.rds.amazonaws.com
DB_PORT=5432
DB_NAME=maestrohwithit_dev
DB_USER=maestrohwithitadmin
DB_PASSWORD=DevPass123!SecureRandom

# JWT
JWT_SECRET=$(openssl rand -base64 32)
JWT_EXPIRES_IN=24h

# AWS
AWS_REGION=us-east-2
S3_BUCKET=dev-maestrohwithit-assets-$(aws sts get-caller-identity --query Account --output text)

# Redis (will add later)
REDIS_HOST=localhost
REDIS_PORT=6379
EOF
```

#### 5.3 Create Dockerfile

```dockerfile
# Dockerfile
FROM node:18-alpine

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci --only=production

# Copy application code
COPY . .

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD node -e "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

# Start application
CMD ["node", "src/server.js"]
```

#### 5.4 Deploy to EC2

```bash
# Copy files to EC2
scp -i ~/.ssh/maestrohwithit-dev-key -r . ec2-user@$EC2_IP:/home/ec2-user/app/

# SSH to EC2
ssh -i ~/.ssh/maestrohwithit-dev-key ec2-user@$EC2_IP

# On EC2: Build and run
cd /home/ec2-user/app
docker build -t maestrohwithit-api:dev .
docker run -d --name maestrohwithit-api \
  --env-file .env \
  -p 80:3000 \
  --restart unless-stopped \
  maestrohwithit-api:dev

# Check logs
docker logs -f maestrohwithit-api
```

**Output:**
```
üöÄ maestrohwithit Property Booking API
üìä Environment: development
üóÑÔ∏è  Database: Connected to dev-maestrohwithit-db.abc123xyz.us-east-2.rds.amazonaws.com
‚úÖ Server listening on port 3000
```

### Day 6: Database Migrations

#### 6.1 Run Database Migrations

```bash
# SSH to EC2
ssh -i ~/.ssh/maestrohwithit-dev-key ec2-user@$EC2_IP

# Run migrations inside container
docker exec maestrohwithit-api npm run migrate

# Seed sample data
docker exec maestrohwithit-api npm run seed
```

**Sample Migration:**
```sql
-- migrations/001_initial_schema.sql
CREATE TABLE properties (
  id SERIAL PRIMARY KEY,
  title VARCHAR(255) NOT NULL,
  description TEXT,
  price_per_night DECIMAL(10,2) NOT NULL,
  bedrooms INTEGER,
  bathrooms INTEGER,
  location VARCHAR(255),
  image_url TEXT,
  status VARCHAR(50) DEFAULT 'available',
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE bookings (
  id SERIAL PRIMARY KEY,
  property_id INTEGER REFERENCES properties(id),
  user_id INTEGER NOT NULL,
  check_in DATE NOT NULL,
  check_out DATE NOT NULL,
  total_price DECIMAL(10,2),
  status VARCHAR(50) DEFAULT 'pending',
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_property_status ON properties(status);
CREATE INDEX idx_booking_dates ON bookings(check_in, check_out);
```

### Day 7: Testing & Validation

#### 7.1 API Testing

```bash
# Get EC2 public IP
EC2_IP=$(cd ~/maestrohwithit-infra/environments/dev && terraform output -json ec2_public_ips | jq -r '.[0]')

# Health check
curl http://$EC2_IP/health

# Create a property
curl -X POST http://$EC2_IP/api/properties \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Luxury Downtown Apartment",
    "description": "Beautiful 2BR apartment in the heart of downtown",
    "price_per_night": 150.00,
    "bedrooms": 2,
    "bathrooms": 2,
    "location": "Downtown, City Center"
  }'

# List properties
curl http://$EC2_IP/api/properties

# Create a booking
curl -X POST http://$EC2_IP/api/bookings \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -d '{
    "property_id": 1,
    "check_in": "2024-02-01",
    "check_out": "2024-02-05"
  }'
```

**Response:**
```json
{
  "success": true,
  "data": {
    "id": 1,
    "property_id": 1,
    "check_in": "2024-02-01",
    "check_out": "2024-02-05",
    "total_price": 600.00,
    "status": "confirmed"
  }
}
```

---

## Stage 3: Staging Deployment (Week 3)

### Day 8: Prepare Staging Environment

#### 8.1 Deploy Staging Infrastructure via GitHub Actions

```bash
# Commit infrastructure changes
cd ~/maestrohwithit-infra
git add environments/staging/
git commit -m "feat: configure staging environment"
git push origin main

# This triggers GitHub Actions workflow
# GitHub Actions ‚Üí terraform-staging.yaml runs automatically
```

**GitHub Actions Log:**
```
‚úÖ Terraform Lint & Format Check
‚úÖ Security Scan (tfsec)
‚úÖ Security Scan (Checkov)
‚úÖ Terraform Plan
‚úÖ Terraform Apply

Staging infrastructure deployed successfully!
Outputs:
  vpc_id = vpc-staging123
  rds_endpoint = staging-maestrohwithit-db.xyz.us-east-2.rds.amazonaws.com
  ec2_public_ip = 3.145.XXX.XXX
```

#### 8.2 Configure Staging Database

```bash
# Create staging secrets
aws secretsmanager create-secret \
  --name /maestrohwithit/staging/rds/master-password \
  --secret-string '{
    "username":"maestrohwithitadmin",
    "password":"StagingPass456!SecureRandom",
    "dbname":"maestrohwithit_staging"
  }' \
  --region us-east-2 \
  --tags Key=Environment,Value=staging

# Create API keys for staging
aws secretsmanager create-secret \
  --name /maestrohwithit/staging/api/jwt-secret \
  --secret-string "$(openssl rand -base64 64)" \
  --region us-east-2 \
  --tags Key=Environment,Value=staging
```

### Day 9: Deploy Application to Staging

####9.1 Setup EKS Cluster (Staging)

```bash
# Add EKS module to staging
cd ~/maestrohwithit-infra/environments/staging

# Create eks.tf
cat > eks.tf <<'EOF'
module "eks" {
  source = "../../modules/eks"

  cluster_name        = "${var.environment}-${var.application}-cluster"
  cluster_version     = "1.28"
  vpc_subnets         = module.vpc.app_subnet_ids
  
  node_group_name     = "${var.environment}-nodes"
  node_instance_type  = ["t3.small"]
  node_disk_size      = 20
  
  # Access
  principal_arn       = "arn:aws:iam::123456789012:user/devops-user"
  kubernetes_groups   = ["system:masters"]
  access_policy_arn   = "arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy"
  
  # Addons
  eks_addons = {
    "coredns"                = "v1.10.1-eksbuild.4"
    "vpc-cni"                = "v1.15.1-eksbuild.1"
    "kube-proxy"             = "v1.28.2-eksbuild.2"
    "eks-pod-identity-agent" = "v1.0.0-eksbuild.1"
  }
  
  policy_arns = [
    "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy",
    "arn:aws:iam::aws:policy/AmazonEKSVPCResourceController",
    "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy",
    "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy",
    "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  ]
}
EOF

# Deploy EKS
terraform apply -var-file=terraform.tfvars
```

#### 9.2 Configure kubectl

```bash
# Update kubeconfig
aws eks update-kubeconfig \
  --name staging-maestrohwithit-cluster \
  --region us-east-2

# Verify connection
kubectl get nodes
```

**Output:**
```
NAME                                        STATUS   ROLES    AGE   VERSION
ip-10-1-4-123.us-east-2.compute.internal   Ready    <none>   5m    v1.28.2-eks-xxx
ip-10-1-5-124.us-east-2.compute.internal   Ready    <none>   5m    v1.28.2-eks-xxx
```

#### 9.3 Deploy Application to Kubernetes

**Create Kubernetes manifests:**

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: maestrohwithit-api
  namespace: default
  labels:
    app: maestrohwithit-api
    environment: staging
spec:
  replicas: 2
  selector:
    matchLabels:
      app: maestrohwithit-api
  template:
    metadata:
      labels:
        app: maestrohwithit-api
    spec:
      containers:
      - name: api
        image: 123456789012.dkr.ecr.us-east-2.amazonaws.com/maestrohwithit-api:staging-v1.0.0
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "staging"
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: rds-credentials
              key: host
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: rds-credentials
              key: password
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: maestrohwithit-api-service
spec:
  type: LoadBalancer
  selector:
    app: maestrohwithit-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
```

**Deploy:**

```bash
# Create namespace
kubectl create namespace maestrohwithit

# Create secrets
kubectl create secret generic rds-credentials \
  --from-literal=host=staging-maestrohwithit-db.xyz.us-east-2.rds.amazonaws.com \
  --from-literal=username=maestrohwithitadmin \
  --from-literal=password=StagingPass456!SecureRandom \
  --namespace=maestrohwithit

# Deploy application
kubectl apply -f k8s/deployment.yaml -n maestrohwithit

# Check deployment
kubectl get deployments -n maestrohwithit
kubectl get pods -n maestrohwithit
kubectl get svc -n maestrohwithit
```

**Output:**
```
NAME         READY   UP-TO-DATE   AVAILABLE   AGE
maestrohwithit-api    2/2     2            2           2m

NAME                        READY   STATUS    RESTARTS   AGE
maestrohwithit-api-7d4b5c8f9-abc12   1/1     Running   0          2m
maestrohwithit-api-7d4b5c8f9-def34   1/1     Running   0          2m

NAME                TYPE           CLUSTER-IP      EXTERNAL-IP
maestrohwithit-api-service   LoadBalancer   10.100.10.10    a1b2c3d4.us-east-2.elb.amazonaws.com
```

### Day 10: QA Testing in Staging

#### 10.1 Load Testing

```bash
# Install Apache Bench
sudo yum install httpd-tools -y

# Run load test
ab -n 1000 -c 10 http://a1b2c3d4.us-east-2.elb.amazonaws.com/api/properties
```

**Results:**
```
Requests per second:    245.32 [#/sec] (mean)
Time per request:       40.761 [ms] (mean)
Transfer rate:          89.45 [Kbytes/sec] received

Percentage of requests served within a certain time (ms)
  50%     35
  66%     38
  75%     40
  80%     42
  90%     48
  95%     55
  98%     68
  99%     85
 100%    125 (longest request)
```

#### 10.2 Monitor CloudWatch

```bash
# View application logs
kubectl logs -f deployment/maestrohwithit-api -n maestrohwithit

# Check CloudWatch metrics
aws cloudwatch get-metric-statistics \
  --namespace AWS/EKS \
  --metric-name node_cpu_utilization \
  --dimensions Name=ClusterName,Value=staging-maestrohwithit-cluster \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Average
```

---

## Stage 4: Production Launch (Week 4)

### Day 11: Production Infrastructure

#### 11.1 Manual Production Deployment

```bash
# GitHub Actions ‚Üí Manually trigger production workflow
# 1. Go to Actions tab
# 2. Select "Terraform Production Environment"
# 3. Click "Run workflow"
# 4. Select action: "plan"
# 5. Review plan output carefully

# After plan approval:
# 6. Run workflow again with action: "apply"
# 7. Requires designated reviewer approval
# 8. Wait for approval and deployment
```

**Infrastructure Checklist:**
- ‚úÖ Multi-AZ VPC (3 AZs)
- ‚úÖ EKS cluster with 3 nodes
- ‚úÖ RDS Multi-AZ
- ‚úÖ Application Load Balancer
- ‚úÖ Auto Scaling Groups
- ‚úÖ CloudWatch Alarms configured
- ‚úÖ VPC Flow Logs enabled
- ‚úÖ AWS Backup enabled (30-day retention)
- ‚úÖ S3 buckets for logs/backups

### Day 12: Production Database Setup

#### 12.1 Create Production Secrets

```bash
# Generate strong passwords
PROD_DB_PASSWORD=$(openssl rand -base64 32)
PROD_JWT_SECRET=$(openssl rand -base64 64)

# Store in Secrets Manager
aws secretsmanager create-secret \
  --name /maestrohwithit/prod/rds/master-password \
  --secret-string "{
    \"username\":\"maestrohwithitadmin\",
    \"password\":\"${PROD_DB_PASSWORD}\",
    \"dbname\":\"maestrohwithit_production\"
  }" \
  --region us-east-2 \
  --tags Key=Environment,Value=prod Key=Backup,Value=true

aws secretsmanager create-secret \
  --name /maestrohwithit/prod/api/jwt-secret \
  --secret-string "${PROD_JWT_SECRET}" \
  --region us-east-2 \
  --tags Key=Environment,Value=prod
```

#### 12.2 Enable Automated Backups

```bash
# Tag RDS for backup
aws rds add-tags-to-resource \
  --resource-name arn:aws:rds:us-east-2:123456789012:db:prod-maestrohwithit-db \
  --tags Key=Backup,Value=true Key=Environment,Value=prod

# Verify backup plan
aws backup list-backup-plans

# Check first backup
aws backup list-backup-jobs \
  --by-state COMPLETED \
  --max-results 5
```

### Day 13: Production Application Deployment

#### 13.1 Build Production Image

```bash
# Build optimized production image
cd property-booking-api

docker build \
  --build-arg NODE_ENV=production \
  --tag maestrohwithit-api:prod-v1.0.0 \
  .

# Push to ECR
aws ecr get-login-password --region us-east-2 | \
  docker login --username AWS --password-stdin \
  123456789012.dkr.ecr.us-east-2.amazonaws.com

docker tag maestrohwithit-api:prod-v1.0.0 \
  123456789012.dkr.ecr.us-east-2.amazonaws.com/maestrohwithit-api:prod-v1.0.0

docker push 123456789012.dkr.ecr.us-east-2.amazonaws.com/maestrohwithit-api:prod-v1.0.0
```

#### 13.2 Deploy to Production EKS

```yaml
# k8s/prod/deployment.yaml with production settings
apiVersion: apps/v1
kind: Deployment
metadata:
  name: maestrohwithit-api
  namespace: production
spec:
  replicas: 3  # Higher for production
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0  # Zero downtime
  # ... rest similar to staging but with prod image
```

```bash
# Deploy to production
kubectl create namespace production
kubectl apply -f k8s/prod/ -n production

# Monitor rollout
kubectl rollout status deployment/maestrohwithit-api -n production
```

### Day 14: DNS & SSL Configuration

#### 14.1 Configure Route53

```bash
# Get Load Balancer DNS
LB_DNS=$(kubectl get svc maestrohwithit-api-service -n production \
  -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

# Create Route53 record
aws route53 change-resource-record-sets \
  --hosted-zone-id Z1234567890ABC \
  --change-batch '{
    "Changes": [{
      "Action": "CREATE",
      "ResourceRecordSet": {
        "Name": "api.maestrohwithit.com",
        "Type": "CNAME",
        "TTL": 300,
        "ResourceRecords": [{"Value": "'"$LB_DNS"'"}]
      }
    }]
  }'
```

#### 14.2 Enable HTTPS

```bash
# Request ACM certificate
aws acm request-certificate \
  --domain-name api.maestrohwithit.com \
  --validation-method DNS \
  --region us-east-2

# Configure ingress with cert
kubectl apply -f k8s/prod/ingress-tls.yaml
```

**Production is LIVE! üéâ**  
**URL:** `https://api.maestrohwithit.com`

---

## Stage 5: Scaling & Optimization (Month 2)

### Week 5: Monitoring & Alerts

#### Configure SNS Notifications

```bash
# Create alarm topic
aws sns create-topic --name prod-maestrohwithit-critical-alarms

# Subscribe email
aws sns subscribe \
  --topic-arn arn:aws:sns:us-east-2:123456789012:prod-maestrohwithit-critical-alarms \
  --protocol email \
  --notification-endpoint devops@maestrohwithit.com

# Confirm subscription (check email)
```

#### Custom CloudWatch Dashboard

```bash
# Create dashboard
aws cloudwatch put-dashboard \
  --dashboard-name maestrohwithitProduction \
  --dashboard-body file://dashboards/production.json
```

### Week 6: Auto Scaling

#### Configure HPA (Horizontal Pod Autoscaler)

```yaml
# k8s/prod/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: maestrohwithit-api-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: maestrohwithit-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

```bash
kubectl apply -f k8s/prod/hpa.yaml
kubectl get hpa -n production
```

---

## Stage 6: Disaster Recovery Testing (Month 3)

### Scenario 1: RDS Failure Recovery

```bash
# 1. Create manual snapshot before test
aws rds create-db-snapshot \
  --db-instance-identifier prod-maestrohwithit-db \
  --db-snapshot-identifier prod-dr-test-$(date +%Y%m%d-%H%M%S)

# 2. Simulate failure (delete instance)
aws rds delete-db-instance \
  --db-instance-identifier prod-maestrohwithit-db \
  --skip-final-snapshot  # Only for DR test!

# 3. Restore from latest automated backup
LATEST_SNAPSHOT=$(aws rds describe-db-snapshots \
  --db-instance-identifier prod-maestrohwithit-db \
  --query "DBSnapshots | sort_by(@, &SnapshotCreateTime) | [-1].DBSnapshotIdentifier" \
  --output text)

aws rds restore-db-instance-from-db-snapshot \
  --db-instance-identifier prod-maestrohwithit-db-restored \
  --db-snapshot-identifier $LATEST_SNAPSHOT \
  --db-instance-class db.t3.medium \
  --multi-az

# 4. Update application config
kubectl set env deployment/maestrohwithit-api \
  DB_HOST=prod-maestrohwithit-db-restored.xyz.us-east-2.rds.amazonaws.com \
  -n production

# 5. Verify recovery
kubectl rollout status deployment/maestrohwithit-api -n production
```

**Recovery Time:** 15 minutes ‚úÖ  
**Data Loss:** 0 minutes (recovered from 5-minute-old automated snapshot) ‚úÖ

### Scenario 2: Complete AZ Failure

```bash
# Simulate AZ failure by cordoning nodes
kubectl cordon ip-10-2-1-xxx.us-east-2.compute.internal

# Kubernetes automatically reschedules pods to healthy AZs
kubectl get pods -n production -o wide

# Verify application accessibility
curl https://api.maestrohwithit.com/health
```

**Downtime:** 0 seconds (seamless failover) ‚úÖ

---

## üìä Production Metrics After 3 Months

### Infrastructure Stats

| Metric | Value |
|--------|-------|
| **Uptime** | 99.98% |
| **Deployments** | 47 |
| **Avg Deploy Time** | 8 minutes |
| **Failed Deployments** | 0 |
| **DR Tests** | 3 (all successful) |

### Application Performance

| Metric | Value |
|--------|-------|
| **Avg Response Time** | 42ms |
| **P95 Response Time** | 85ms |
| **P99 Response Time** | 150ms |
| **Requests/day** | 2.5M |
| **Error Rate** | 0.02% |

### Cost Analysis

| Environment | Monthly Cost | Notes |
|-------------|-------------|-------|
| **Dev** | $58 | Stopped nights/weekends |
| **Staging** | $143 | Always on, smaller instances |
| **Production** | $487 | HA, backups, monitoring |
| **Total** | **$688** | ~$8,256/year |

### Cost Savings Implemented

- ‚úÖ Reserved Instances for production: -30% ($146/month saved)
- ‚úÖ S3 Intelligent-Tiering: -25% on storage ($12/month saved)
- ‚úÖ Dev environment shutdown automation: -60% ($70/month saved)

**Total Savings:** $228/month (~$2,736/year)

---

## üéì Key Lessons Learned

### What Worked Well

1. **Multi-Environment Strategy** - Clear separation prevented prod issues
2. **Infrastructure as Code** - Easy to replicate and version
3. **Automated Backups** - Saved us during accidental data deletion
4. **Security Scanning** - Caught 15 vulnerabilities before production
5. **Monitoring** - Proactive alerts prevented 3 outages

### What We'd Do Differently

1. **Earlier Load Testing** - Found scaling issues late in staging
2. **Cost Budgets** - Set up from day 1, not month 2
3. **Secrets Rotation** - Should have automated from start
4. **Documentation** - Keep updated as infrastructure evolves
5. **DR Testing** - Should test more frequently (monthly vs quarterly)

---

## üöÄ Next Steps

### Short Term (Next Month)
- [ ] Implement Redis caching (ElastiCache)
- [ ] Add CDN (CloudFront) for static assets
- [ ] Set up log aggregation (ELK stack)
- [ ] Implement rate limiting
- [ ] Add API gateway

### Medium Term (Next Quarter)
- [ ] Multi-region deployment
- [ ] Cross-region disaster recovery
- [ ] Advanced monitoring (APM tools)
- [ ] Cost optimization review
- [ ] Security audit

### Long Term (Next Year)
- [ ] Microservices architecture
- [ ] Service mesh (Istio)
- [ ] Advanced auto-scaling
- [ ] ML-based anomaly detection
- [ ] Zero-trust security model

---

## üìö Additional Resources

- [Terraform AWS Provider Docs](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [EKS Best Practices](https://aws.github.io/aws-eks-best-practices/)
- [RDS Best Practices](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_BestPractices.html)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)

---

**Deployment Success Rate:** 100% ‚úÖ  
**From Idea to Production:** 4 weeks  
**Team Satisfaction:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Welcome to production-ready infrastructure!** üéâ
